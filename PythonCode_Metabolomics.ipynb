{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabolomics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to analyse and report the analysis, I use jupyter notebook, along with Pandas to parse the given raw data file for further analysis. In order to use pandas, it is imported into the notebook first. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the Raw data file:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importing the modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the modules\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reading the Excel file into a pandas's dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the path for the file location and it could be changed by any user to make use of it.\n",
    "PATH = \"C:/Users/mayur/Documents/GitHub/Intern_project/FileFolder/\"\n",
    "\n",
    "# Reading the Excel file as a dataframe using pandas and seting ID as a index row.\n",
    "CC_metabolite = pd.read_excel(PATH + \"cellC_meta.xlsx\",index_col = \"ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Parsing the dataframe to remove the blank treatment rows to avoid redundancy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command is to remove rows from a dataframe.\n",
    "# Selecting the treatment column name with Blank rows and dropping them\n",
    "\n",
    "filteredD = CC_metabolite.drop(CC_metabolite[CC_metabolite[\"Treatments\"]==\"Blank\"].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting and changing the time column names to 30 and 90 mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this splits the time column elements and stores as a list. we only need 30 and 90 mins from the given string.\n",
    "\n",
    "str_split = filteredD[\"Time\"].str.split(\"_\",n=2,expand=True)[1]\n",
    "list_str = list(str_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserting the column to specific index position '2' as the new column is always added at the end of the dataframe table.\n",
    "# Specifying to allow the duplicate names as 30 and 90 mins are...\n",
    "\n",
    "filteredD.insert(2,\"time\", list_str,allow_duplicates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dropping the original time column..\n",
    "\n",
    "final_data = filteredD.drop([\"Time\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean values are calculated for duplicate values of Treatment and Time columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using groupby for treatment and time columns as they have duplicated values and then calculating the mean values.\n",
    "# Final data contains 16 rows of treatments and 70 columns of metabolite IDs.\n",
    "\n",
    "avg_duplicated = final_data.groupby([\"Treatments\",\"time\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the Parsed file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the parsed file in the home directory in Excel format.\n",
    "\n",
    "PATH = \"C:/Users/mayur/Documents/GitHub/Intern_project/FileFolder/\"\n",
    "\n",
    "avg_duplicated.to_excel(PATH + \"metabolite_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subset the file into two based on TIME variable:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Subset 30 Mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this, the final data after parsing is taken and subset into 30 mins based on time column.\n",
    "# Index is set to treatment as there are no duplicate names.\n",
    "\n",
    "time_30min = avg_duplicated[avg_duplicated[\"time\"] == \"30Min\"].set_index(\"Treatments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the subset data file in Excel format to use it in R.\n",
    "\n",
    "time_30min.to_excel(PATH + \"subset_30min.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Subset 90 Mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this, the final data after parsing is taken and subset into 90 mins based on time column.\n",
    "# Index is set to treatment as there are no duplicate names.\n",
    "\n",
    "time_90min = avg_duplicated[avg_duplicated[\"time\"] == \"90Min\"].set_index(\"Treatments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the subset data file in Excel format to use it in R.\n",
    "\n",
    "time_90min.to_excel(PATH + \"subset_90min.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of Fold Change Values for subset data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing a class to calculate the fold change values for both subset data\n",
    "class Metabolomics:\n",
    "    \n",
    "    #Constructor takes in the subset data file each time\n",
    "    def __init__(self,file):\n",
    "        self.file = file\n",
    "       \n",
    "    #Writing a method parsing file\n",
    "    def parsingfile(self):\n",
    "        \n",
    "        #taking first seven columns and saving it as treatment groups\n",
    "        self.treatGrp = self.file.iloc[:,0:7]\n",
    "        #taking last column from the file and saving it in a variable control group.\n",
    "        self.controlGrp = self.file.iloc[:,7]\n",
    "    \n",
    "    #This method calculates the fold change values between each treatment group and control group\n",
    "    def foldchange_cal(self):\n",
    "        \n",
    "        #assigning metabolite ids into list to a variable.\n",
    "        index_lst = self.treatGrp.index.values.tolist()\n",
    "       \n",
    "        #assigning the local variables in form of list to make a dataframe file.\n",
    "        treatments = []\n",
    "        lst_values = []\n",
    "\n",
    "        #iterating every treatment group column\n",
    "        for i,j in self.treatGrp.iteritems():\n",
    "            #calculating fold change values using ratio between treatment/control group\n",
    "            foldchange = j/self.controlGrp\n",
    "            #appending each of the values to list\n",
    "            lst_values.append(foldchange.tolist())\n",
    "            #appending every treatment group into a list\n",
    "            treatments.append(i)\n",
    "            \n",
    "        #creating dataframe by taking in all the list variables into it.\n",
    "        #treatment group as index and columns as metabolite ids.\n",
    "        #finally transposing the dataframe and return it into an argument in main code.\n",
    "        FC_data = pd.DataFrame(lst_values,index=treatments,columns=index_lst).T\n",
    "        return FC_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropping the column time from both subset data as it isn't required for this task and then transpose it.\n",
    "time_30 = time_30min.drop(\"time\",axis=1).T\n",
    "time_90 = time_90min.drop(\"time\",axis=1).T\n",
    "\n",
    "################ subset 30 min ###################\n",
    "#passing the 30 min subset data into a class metabolomics..\n",
    "subset1 = Metabolomics(time_30)\n",
    "#CALLING THE METHODS FROM THE GIVEN CLASS\n",
    "subset1.parsingfile()\n",
    "FC_data = subset1.foldchange_cal()\n",
    "#returned dataframe fold change values is saved into an excel in particular path.\n",
    "FC_data.to_excel(PATH + \"FC_30min.xlsx\")\n",
    "\n",
    "################ subset 90 min ###################\n",
    "#passing the 90 min subset data into a class metabolomics..\n",
    "subset2 = Metabolomics(time_90)\n",
    "#CALLING THE METHODS FROM THE GIVEN CLASS\n",
    "subset2.parsingfile()\n",
    "FC_data = subset2.foldchange_cal()\n",
    "#returned dataframe fold change values is saved into an excel in particular path.\n",
    "FC_data.to_excel(PATH + \"FC_90min.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
